{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4526114c-cf47-4806-b864-43a31e8a25d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('/Workspace/Users/luisfdiaz@bcp.com.pe/Modulo de Seguimiento/')\n",
    "\n",
    "import SegScore as rmm\n",
    "importlib.reload(rmm)\n",
    "\n",
    "# Librerias y fuciones generales\n",
    "from pyspark.sql.functions import date_format, expr, to_date, date_sub, add_months, col, when, coalesce, trim, broadcast, avg, max, min, lit, concat, window, round as colround, upper, abs as sparkabs,greatest\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import StorageLevel\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eda94aa5-6e3b-4824-9ee5-35e07d1d8193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Cuartiles\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def categorize_by_quintiles(df, column_names, filter_condition, quintile_probabilities=[0.25, 0.5, 0.75, 1.0], relative_error=0.01):\n",
    "    for column in column_names:\n",
    "        # Filtrar y calcular los quintiles\n",
    "        quintiles = df.filter(filter_condition).approxQuantile(column, quintile_probabilities, relative_error)\n",
    "        Minimo = df.agg({column: \"min\"}).collect()[0][0]\n",
    "        \n",
    "        # Crear la nueva columna categorizada\n",
    "        df = df.withColumn(\n",
    "            f'{column}_Q',\n",
    "            F.when(F.col(column) <= quintiles[0], f\"1. {format(Minimo, '.3f')} - {format(quintiles[0], '.3f')}\")\n",
    "             .when(F.col(column) <= quintiles[1], f\"2. {format(quintiles[0], '.3f')} - {format(quintiles[1], '.3f')}\")\n",
    "             .when(F.col(column) <= quintiles[2], f\"3. {format(quintiles[1], '.3f')} - {format(quintiles[2], '.3f')}\")\n",
    "             .when(F.col(column) <= quintiles[3], f\"4. {format(quintiles[2], '.3f')} - {format(quintiles[3], '.3f')}\")\n",
    "             .otherwise(\"98. Missing\")\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c099d4c4-6b98-4254-bc16-25ed666fe7c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Mostrar los duplicados\n",
    "def print_res(sparkf_df):\n",
    "  import pandas as pd\n",
    "  pd.set_option('display.max_rows', None)\n",
    "  pd.set_option('display.max_columns', None)\n",
    "  pd_spark_df = sparkf_df.toPandas()\n",
    " \n",
    "  return pd_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b04a75-2d14-4cd6-ab3b-ade8f6850557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_repeated_columns(df):\n",
    "    column_names = df.columns\n",
    "    column_counts = Counter(column_names)\n",
    "    repeated_columns = [col for col, count in column_counts.items() if count > 1]\n",
    "    return repeated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9917ba7f-d4eb-4e5d-81e8-a0ccb8e1df2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_missing_columns(df1, df2):\n",
    "    columns_df1 = set(df1.columns)\n",
    "    columns_df2 = set(df2.columns)\n",
    "    \n",
    "    missing_in_df2 = columns_df1 - columns_df2\n",
    "    missing_in_df1 = columns_df2 - columns_df1\n",
    "    \n",
    "    print(\"Columnas en df1 pero no en df2:\", missing_in_df2)\n",
    "    print(\"Columnas en df2 pero no en df1:\", missing_in_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b1d5995-3a03-40ff-bd84-56a66c3ef6f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generar_codmes(inicio, final):\n",
    "    codmes_list = []\n",
    "    anio_inicial = inicio // 100\n",
    "    mes_inicial = inicio % 100\n",
    "    \n",
    "    anio_final = final // 100\n",
    "    mes_final = final % 100\n",
    "    \n",
    "    anio = anio_inicial\n",
    "    mes = mes_inicial\n",
    "    \n",
    "    # Generar la lista hasta el mes final\n",
    "    while (anio < anio_final) or (anio == anio_final and mes <= mes_final):\n",
    "        codmes_list.append(anio * 100 + mes)\n",
    "        mes += 1\n",
    "        if mes > 12:\n",
    "            mes = 1  # Pasar a enero del siguiente año\n",
    "            anio += 1\n",
    "    return codmes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cb2c3d-518f-47e3-8cbf-e38e03482e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "def dias_atraso(base, identificador, inicio, final): \n",
    "    df_list = []\n",
    "    espacio = generar_codmes(inicio = inicio, final = final)\n",
    "    for codmes in espacio:\n",
    "        numeromes = (codmes // 100) * 12 + (codmes % 100)\n",
    "        codmes_f1 = ((numeromes - 1 + 1) // 12) * 100 + ((numeromes + 11 - 11 * 1) % 12) + 1\n",
    "        codmes_f2 = ((numeromes - 1 + 2) // 12) * 100 + ((numeromes + 11 - 11 * 2) % 12) + 1\n",
    "        codmes_f3 = ((numeromes - 1 + 3) // 12) * 100 + ((numeromes + 11 - 11 * 3) % 12) + 1\n",
    "\n",
    "        df_base = base.filter(f\"CODMES = {codmes}\").select(\"CODMES\", identificador, \"CTDMESMADURACION\", \"MTOSALDOCAPITALSOL\",\"TIPBLOQUEOPRODUCTO\", \"CTDDIAATRASO\")\n",
    "        df_f1 = base.filter(f\"CODMES = {codmes_f1}\").select(\"CODMES\", identificador, \"CTDDIAATRASO\")\n",
    "        df_f2 = base.filter(f\"CODMES = {codmes_f2}\").select(\"CODMES\", identificador, \"CTDDIAATRASO\")\n",
    "        df_f3 = base.filter(f\"CODMES = {codmes_f3}\").select(\"CODMES\", identificador, \"CTDDIAATRASO\")\n",
    "\n",
    "        df_parcial = df_base.alias('A') \\\n",
    "                .join(df_f1.alias('B'), on = identificador, how = 'left') \\\n",
    "                .join(df_f2.alias('C'), on = identificador, how = 'left') \\\n",
    "                .join(df_f3.alias('D'), on = identificador, how = 'left') \\\n",
    "                .selectExpr('A.*', \n",
    "                            'COALESCE(B.CTDDIAATRASO, 0) AS CTDDIAATRASO_F1', \n",
    "                            'COALESCE(C.CTDDIAATRASO, 0) AS CTDDIAATRASO_F2', \n",
    "                            'COALESCE(D.CTDDIAATRASO, 0) AS CTDDIAATRASO_F3')\n",
    "                \n",
    "        df_list.append(df_parcial)\n",
    "        print(f'Iteración {codmes}:', f't0:{codmes}', f't1:{codmes_f1}', f't2:{codmes_f2}', f't3:{codmes_f3}')\n",
    "\n",
    "    df_final = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        df_final = df_final.unionByName(df)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90e5748-4d5e-4ec1-bc35-34e512c33b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def rezago_codmes_col(base, rezago_mes):\n",
    "    for i in range(0, rezago_mes + 1, 1):\n",
    "        base = base.withColumn(f\"CODMES_{i}\", date_format(add_months(to_date(concat(col(\"codmes\"), lit(\"01\")), \"yyyyMMdd\"), -i), \"yyyyMM\"))\n",
    "        base = base.withColumn(f\"CODMES_{i}\", col(f\"CODMES_{i}\").cast(\"integer\"))\n",
    "    return base\n",
    "\n",
    "def avance_codmes_col(base, avance_mes):\n",
    "    for l in range(0, avance_mes + 1, 1):\n",
    "        base = base.withColumn(f\"CODMES_F{l}\", date_format(add_months(to_date(concat(col(\"codmes\"), lit(\"01\")), \"yyyyMMdd\"), l), \"yyyyMM\"))\n",
    "        base = base.withColumn(f\"CODMES_F{l}\", col(f\"CODMES_F{l}\").cast(\"integer\"))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e25b697-b9ec-463f-b541-f2e5521d9a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path_CSV = \"abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/HIPOTECARIO_2025/APP/202503/MM_APPSCORE_GARANTIAHIP\"\n",
    " \n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_GARANTIAHIP_202503;\"\"\")\n",
    " \n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_GARANTIAHIP_202503\n",
    "    USING CSV\n",
    "    OPTIONS (header = \"true\", inferSchema = \"true\",delimiter = \";\")    \n",
    "    LOCATION '{path_CSV}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ced31d0-e22b-47e2-a9fd-3f4d0e38493d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hm_mtz_adm_hipotecario_driver = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_hm_mtz_admision_hipotecario_202503_F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f31b69e8-d066-4cd0-9f85-f2ef99cd70f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hm_adm_gahi_001 = hm_mtz_adm_hipotecario_driver.withColumn(\n",
    "    \"FLG_FINALIDAD\",\n",
    "    when(col(\"DESTIPFINALIDADCREDHIPOTECARIO\").isNull(), lit(1))\n",
    "    .when(col(\"DESTIPFINALIDADCREDHIPOTECARIO\").isin(\n",
    "        \"LIBRE DISPONIBILIDAD\",\n",
    "        \"COMPRA VENTA DE LOCAL COMERCIAL\",\n",
    "        \"C-V/REMODEL/AMPLI DE LOCAL COMERCIAL\",\n",
    "        \"C-V Oficinas/Locales BT\",\n",
    "        \"LIBRE DISP. CON GARANT.LOCAL COMERC.\",\n",
    "        \"MIGRACION DE OTRO BANCO\"\n",
    "    ), lit(1))\n",
    "    .when((col(\"CODMES\") >= 202307) & (col(\"DESTIPFINALIDADCREDHIPOTECARIO\") == \"COMPRA/VENTA BIEN TERMINADO\"), lit(1))\n",
    "    .otherwise(lit(0))\n",
    ").filter(col(\"TIPCREDITO\").isin('GAHI', 'GAHP', 'GAHR', 'GAPC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa4ee6fe-05dc-4c66-836c-549fb279356d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hm_adm_gahi_001.createOrReplaceTempView(\"temp_hm_adm_gahi_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21b55d31-b350-4aba-acc2-27a10a3158e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_espejo=spark.sql(\"select distinct * from catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_GARANTIAHIP_202503\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b22cf4b-711c-40f3-9c75-8d8b482e906e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_espejo.persist(StorageLevel.MEMORY_AND_DISK).count()\n",
    "\n",
    "dup = base_espejo.groupBy( \"CODSOLICITUD\").count().alias(\"count\").filter(col(\"count\")>1)\n",
    "print_res(dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0640e6df-2c21-4889-8657-748ba09e2cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_espejo.createOrReplaceTempView(\"temp_base_espejo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0895ff96-1eca-46e0-ac27-ca0b42de492d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hm_adm_gahi_002 = spark.sql(\"\"\"\n",
    "    SELECT A.*, \n",
    "           /*VARIABLES CALIBRADO*/\n",
    "           D.XB_GAHI,\n",
    "           D.XB_GAHI_PRELIMINAR,\n",
    "           D.XB_NUE_APP_CEF, /*89%*/\n",
    "           D.XB_MODUL_GAHI, /*11%*/\n",
    "           D.LTV_NEW AS LTV_NEW_CAL,\n",
    "           D.LTV_NEW_A2,\n",
    "           D.CTDPLAZOAPROBADO_TP,\n",
    "           D.CTDPLAZOAPROBADO_A2,\n",
    "           D.RIESGO_ZONA2,\n",
    "           D.RIESGO_ZONA2_ST,\n",
    "           D.INGRESO_SOL_CONY_TP,\n",
    "           D.INGRESO_SOL_CONY_D3, \n",
    "           D.FLG_MONTO AS FLG_MONTO_CAL, /*SI >=325,000 FLG_MONTO=1*/\n",
    "           D.PD_GAHI AS PD_GAHI_ESPEJO\n",
    "    FROM temp_hm_adm_gahi_001 A\n",
    "    LEFT JOIN temp_base_espejo D ON A.CODSOLICITUD=D.CODSOLICITUD;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77971c76-702f-423f-b3d1-12c5dc8ac3cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hm_adm_gahi_002.persist(StorageLevel.MEMORY_AND_DISK).count()\n",
    "\n",
    "dup = hm_adm_gahi_002.groupBy(\"codmes\", \"codclaveopecta\").count().alias(\"count\").filter(col(\"count\")>1)\n",
    "print_res(dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ecadee-2d01-4fc1-b624-b5612759968f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add the TOTAL column\n",
    "hm_adm_gahi = hm_adm_gahi_002.withColumn(\"TOTAL\", lit('1'))\n",
    "\n",
    "# Add the PAUTA column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"PAUTA\", when(col(\"SC_GAHI\") >= 345, 1).otherwise(0))\n",
    "\n",
    "# Add the RSC column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"RSC\", when(col(\"SC_GAHI\").isNull(), '99. Missing')\n",
    "                   .when(col(\"SC_GAHI\") < 385, '1. <0 - 385>')\n",
    "                   .when(col(\"SC_GAHI\") < 415, '2. [385 - 415>')\n",
    "                   .when(col(\"SC_GAHI\") < 450, '3. [415 - 450>')\n",
    "                   .when(col(\"SC_GAHI\") < 495, '4. [450 - 495>')\n",
    "                   .when(col(\"SC_GAHI\") >= 495, '5. [495 - +++>')\n",
    "                   .otherwise('98. Otro'))\n",
    "\n",
    "# Add the RPD column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"RPD\", when(col(\"PD_GAHI\").isNull(), '99. Missing')\n",
    "                   .when(col(\"PD_GAHI\") <= 0.005, '1. <0 - 0.5%]')\n",
    "                   .when(col(\"PD_GAHI\") <= 0.010, '2. <0.5 - 1.0%]')\n",
    "                   .when(col(\"PD_GAHI\") <= 0.015, '3. <1.0 - 1.5%]')\n",
    "                   .when(col(\"PD_GAHI\") <= 0.025, '4. <1.5 - 2.5%]')\n",
    "                   .when(col(\"PD_GAHI\") > 0.025, '5. <2.5 - ++>')\n",
    "                   .otherwise('98. Otro'))\n",
    "\n",
    "# Add the MONTO_R column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"MONTO_R\", when(col(\"MTOAPROBADO_SOLES\").isNull(), '99. Missing')\n",
    "                   .when(col(\"MTOAPROBADO_SOLES\") <= 87500, '1. [0 - 87,500]')\n",
    "                   .when(col(\"MTOAPROBADO_SOLES\") <= 140000, '2. <87,500 - 140,000]')\n",
    "                   .when(col(\"MTOAPROBADO_SOLES\") <= 215000, '3. <140,000 - 215,000]')\n",
    "                   .when(col(\"MTOAPROBADO_SOLES\") <= 300000, '4. <215,000 - 300,000]')\n",
    "                   .when(col(\"MTOAPROBADO_SOLES\") <= 600000, '5. <300,000 - 600,000]')\n",
    "                   .otherwise('6. <600,000 - ++>'))\n",
    "\n",
    "# Add the MISS_PD column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"MISS_PD\", when(col(\"PD_GAHI\").isNull(), 1).otherwise(0))\n",
    "\n",
    "# Add the MISS_MONTO column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"MISS_MONTO\", when(col(\"MTOAPROBADO_SOLES\").isNull(), 1).otherwise(0))\n",
    "\n",
    "# Add the RAN_INGR_CY column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"RAN_INGR_CY\", when(col(\"INGRESO_SOL_CONY_TP\").isNull(), '99. Missing')\n",
    "                   .when(col(\"INGRESO_SOL_CONY_TP\") <= 2500, '1. [0 - 2,500]')\n",
    "                   .when(col(\"INGRESO_SOL_CONY_TP\") <= 5000, '2. <2,500 - 5,000]')\n",
    "                   .when(col(\"INGRESO_SOL_CONY_TP\") <= 7500, '3. <5,000 - 7,500]')\n",
    "                   .when(col(\"INGRESO_SOL_CONY_TP\") <= 10000, '4. <7,500 - 10,000]')\n",
    "                   .when(col(\"INGRESO_SOL_CONY_TP\") <= 20000, '5. <10,000 - 20,000]')\n",
    "                   .otherwise('6. <20,000 - ++>'))\n",
    "\n",
    "# Add the FLG_MONTO_R column\n",
    "hm_adm_gahi = hm_adm_gahi.withColumn(\"FLG_MONTO_R\", when(col(\"FLG_MONTO_CAL\").isNull(), '99. Missing')\n",
    "                   .when(col(\"FLG_MONTO_CAL\") == 1, '1. >=325,000')\n",
    "                   .otherwise('2. <325,000'))\n",
    "\n",
    "# Filter the dataframe\n",
    "hm_adm_gahi = hm_adm_gahi.filter(col(\"FLG_FINALIDAD\") == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f43bbe-cf98-4848-ae03-e72c66e5bcb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hm_adm_gahi.createOrReplaceTempView(\"temp_view\")\n",
    "spark.sql(\"CREATE OR REPLACE TABLE catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_HM_ADM_HIP_GAHI_202503_F LOCATION 'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/HIPOTECARIO_2025/APP/202503/T45988_HM_ADM_HIP_GAHI_202503_F' AS SELECT * FROM temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b532219-c463-4833-92b0-048cdbbf94d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Garantia_Hipotecaria",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
